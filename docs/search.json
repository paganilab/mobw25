[
  {
    "objectID": "pages/index.html",
    "href": "pages/index.html",
    "title": "Introduction",
    "section": "",
    "text": "The course will give an overview on how to conceptually approach bioinformatics. During the three days of the course we will dive into a bulk RNA-seq experiment and carry out the main steps of a standard data analysis pipeline."
  },
  {
    "objectID": "pages/index.html#day-1",
    "href": "pages/index.html#day-1",
    "title": "Introduction",
    "section": "Day 1 🤓",
    "text": "Day 1 🤓\n\nSetup RStudio or Posit\nGet familiar with the Posit interface\nLearn about bulk RNA-seq data processing\nDownload the data needed for the workshop"
  },
  {
    "objectID": "pages/index.html#day-2",
    "href": "pages/index.html#day-2",
    "title": "Introduction",
    "section": "Day 2 🧑🏼‍💻",
    "text": "Day 2 🧑🏼‍💻\n\nLearn about data normalization\nLearn about the edgeR package\nExplore different normalization methods\nNormalize the data with functions provided by the edgeR package\nPerform diagnostic and exploratory analysis on the data"
  },
  {
    "objectID": "pages/index.html#day-3",
    "href": "pages/index.html#day-3",
    "title": "Introduction",
    "section": "Day 3 🧙🏼‍♂️",
    "text": "Day 3 🧙🏼‍♂️\n\nLearn about the theory behind differential expression analysis\nPerform differential expression analysis using edgeR\nVisualize the results\nPerform further downstream analysis on interesting gene groups"
  },
  {
    "objectID": "pages/index.html#how-to-reach-us",
    "href": "pages/index.html#how-to-reach-us",
    "title": "Introduction",
    "section": "How To Reach Us",
    "text": "How To Reach Us\n\nAnna Beneggi (anna.beneggi@ifom.eu)\nMattia Toninelli (mattia.toninelli@ifom.eu)\n\n\n\n\nFeel free to drop us an e-mail if you have any curiosity or question!"
  },
  {
    "objectID": "pages/help.html",
    "href": "pages/help.html",
    "title": "Help Page",
    "section": "",
    "text": "In this page you can find some helpful information in case you get lost in the functionality of Posit or R. In any case if you need to troubleshoot anything, please do not hesitate to raise your hand and ask!\n\nThe Posit Interface Died\nIn the case that the Posit interfaces dies, you can follow the instructions on the screen to re-start it. If this happens, all the variables within your session will disappear therefore functions will break. If you already saved the results of the analysis in the results.csv file (on day 3) and the samples table in the samples_table.csv file (on day 1) you can run the following directly from your R console:\n\n# Load existing files for results and samples information\nres <- read.table(\"results.csv\", sep = \",\")\nsamples <- read.table(\"samples_table.csv\", sep = \",\")\n\nIn this way, you should be able to run all the code starting from the “saving results” section. In the case you DID NOT have the files saved, you will have to re-run everything before the point where your R session died, which should not really be a problem if you had all the code written in a script since you can re-run it seamlessly.\n\n\nThe Posit RAM Is Full\nIf you are using Posit and you see the RAM indicator on the upper right part of your screen turning red, you can try to do the following to solve the problem:\n\n# Clean up garbage (unused memory) \ngc()\n\n# In the case we need to remove specific variables\nmyvar <- c(1,2) # A variable\nrm(myvar)"
  },
  {
    "objectID": "pages/project.html",
    "href": "pages/project.html",
    "title": "Project",
    "section": "",
    "text": "It’s time to see how much you can take away from the concepts and the topics of the course! You are going to be working on designing and constructing your own project!"
  },
  {
    "objectID": "pages/project.html#how-does-it-work",
    "href": "pages/project.html#how-does-it-work",
    "title": "Project",
    "section": "How does it work?",
    "text": "How does it work?\nYou will have 5 minutes to organize into groups of approximately the same size, after that you will:\n\nReflect on the Bachelor’s thesis project among the ones in your group\nSelect one project that in your opinion would benefit the most from a bulk RNA-Seq experiment\nDesign your planned experiment by considering the following key points:\n\nWhat is your biological question or hypothesis?\nWhat experimental conditions are required to test your hypothesis?\nHow many biological/technical replicates are necessary for obtaining reliable results?\nIs your experiment well-designed, or are there potential confounding factors?\nWhat type of RNA enrichment method should you use?\nBased on the RNA type you want to analyze (mRNA, miRNA, lncRNA, etc.), do you need a stranded library preparation?\nWhat read length, sequencing depth, and sequencing mode are required for your analysis?\nIf a bioinformatician will perform the analysis of your samples, what metadata should you provide to ensure a well-informed and accurate analysis?\nDo you believe incorporating the analysis of other -OMICS will enhance your experiment? If yes, which ones?\n\nCreate a 1-2 slides presentation to communicate how you would go about planning your project! (remember: you are trying to convince your boss to spend a lot of 💸)\nPresent your work! (nice and easy 🤙🏼)"
  },
  {
    "objectID": "pages/day3.html",
    "href": "pages/day3.html",
    "title": "Day 3",
    "section": "",
    "text": "Learn about the theory behind differential expression analysis (DEA)\nPerform differential expression analysis using edgeR\nVisualize the results\nPerform further downstream analysis on interesting gene groups"
  },
  {
    "objectID": "pages/day3.html#differential-expression-analysis",
    "href": "pages/day3.html#differential-expression-analysis",
    "title": "Day 3",
    "section": "Differential Expression Analysis",
    "text": "Differential Expression Analysis\n\n🤔 At this point we should remind ourselves of why we decided to perform an RNA-seq experiment, do you remember?\n\nThe main purpose of the steps we performed previously is to get to this point with a fair knowledge of the data at hand, all the steps have to be repeated each time one starts with some fresh new data (no data is the same!!). Now we can start performing differential expression analysis with the edgeR package. The main concept behind it is to contrast two categories of our interest in the data (i.e. CD8+ Tex vs CD8+ Trest) and check which genes are predominantly (defined in a statistical sense) expressed in one category as opposed to the other. As introduced previously, we tell edgeR which comparisons to perform through the design formula we specified above when we created our DGEList object dds. We can recap the design formula that we specified.\n\n# Check out the design formula we specified (do not copy this, you should have it in your variable `design`)\n~ Donor + SampleGroup\n\nWith that design formula we are telling the software that we are interested in checking for the gene expression differences happening between the categories present in the SampleGroup column of our samples table while simultaneously correcting for the possible uninteresting differences that can arise across different donors, whose information is stored in the Donor column of the samples table which we can check out below. The Donor therefore represents our batch whose effect we are trying to correct for.\n\n\n\n\n \n  \n      \n    Donor \n    SampleGroup \n  \n \n\n  \n    BSSE_QGF_204446 \n    HD276 \n    Trest \n  \n  \n    BSSE_QGF_204447 \n    HD276 \n    Ttumor \n  \n  \n    BSSE_QGF_204448 \n    HD276 \n    Teff \n  \n  \n    BSSE_QGF_204449 \n    HD276 \n    Tex \n  \n  \n    BSSE_QGF_204450 \n    HD280 \n    Trest \n  \n  \n    BSSE_QGF_204451 \n    HD280 \n    Ttumor \n  \n\n\n\n\n\nThe categories are exactly the ones we have been plotting all along up to this point (the different CD8+ T-cell types).\n\n💡 Given that we have four differences categories (these are also called levels in R) in our SampleGroup column (which can also be called a factor in R), edgeR could perform different comparisons since these are pairwise. We need to keep in mind that our reference values are referred to the CD8+ Teff group!\n\n\nThe Main edgeR Function\nLet’s perform differential expression analysis with edgeR on our dataset using the main function for the task in the package, glmTest(). Without going into the mathematical details, this function fits a generalized linear model (GLM) to the data in order to perform inference and decide which genes are statistically up- or down-regulated. We first need to compute gene-wise dispersion estimate with the function estimateDisp(). These are needed by the model in order for its underlying assumptions to hold true. We can visually inspect the fit of the dispersion estimates below.\n\n# First we fit gene-wise dispersion estimates to accomodate the theoretical assumptions of the model\ndds <- estimateDisp(dds, design, robust=TRUE)\n\n# Plot the fitted dispersion values\nplotBCV(dds)\n\n\n\n\n\n\n\n\nFrom the dispersion estimate we can see that we are capturing and modelling efficiently the gene-wise dispersion in the dataset which is intrinsically present due to variation. This variation is quantified in edgeR with a BCV or a Biological Coefficient of Variation which takes into account both unwanted biological variability (specified in the design) and technical variation.\n\n# Fit the GLM\nfit <- glmFit(dds, design)\n\n# Perform differential expression testing given the design formula we wrote previously\nlrt <- glmLRT(fit, coef=7)\n\nNotice how we did not use the transformed version of the dataset (log2dds) but we started from the object dds. As previously mentioned, the package needs to start from raw count data to correctly assess differences in gene expression.\nLet’s say that we are very interested in the differences occurring between CD8+ Tex and CD8+ Teff cells. The reason why we specified coef=7 in the code above is explained by how edgeR interprets the design matrix that we built previously, which specifies the kinds of comparison to make. If we take a look at it we can see how the 7th column is the one related to the Tex group, the one we want to compare against our reference group Teff.\n\nhead(design, 4)\n\n\n\n\n\n \n  \n    (Intercept) \n    donorHD280 \n    donorHD286 \n    donorHD287 \n    sample_groupTrest \n    sample_groupTtumor \n    sample_groupTex \n  \n \n\n  \n    1 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n  \n  \n    1 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n  \n  \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n  \n  \n    1 \n    1 \n    0 \n    0 \n    1 \n    0 \n    0 \n  \n  \n    1 \n    1 \n    0 \n    0 \n    0 \n    1 \n    0 \n  \n  \n    1 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    1 \n    1 \n    0 \n    0 \n    0 \n    0 \n    1 \n  \n  \n    1 \n    0 \n    1 \n    0 \n    1 \n    0 \n    0 \n  \n  \n    1 \n    0 \n    1 \n    0 \n    0 \n    1 \n    0 \n  \n  \n    1 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    1 \n    0 \n    1 \n    0 \n    0 \n    0 \n    1 \n  \n  \n    1 \n    0 \n    0 \n    1 \n    1 \n    0 \n    0 \n  \n  \n    1 \n    0 \n    0 \n    1 \n    0 \n    1 \n    0 \n  \n  \n    1 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n  \n  \n    1 \n    0 \n    0 \n    1 \n    0 \n    0 \n    1 \n  \n\n\n\n\n\n\n💡 In GLMs, design matrices are built to communicate the way we want to model samples when testing for gene expression differences. Some packages keep this aspect less exposed than other to allow users which are less familiar with the mathematical concepts to still use the package. Often, better knowledge allows better control and flexibility over what we do, at the cost of greater responsibility!\n\n\n\nExploring Results\nAfter having used the main edgeR function, we can actively explore the results of the analysis for the comparisons of our interest. For example we might want to check if any gene is up-regulated during the process of CD8+ T-cell exhaustion. We can later filter the results based adjusted P-value used to accept or reject the null hypothesis (\\(H_{0}\\)) of a gene NOT being differentially expressed between the two conditions.\nWith the code below we can extract a table that we call res which contains the results for every single gene, stored in separate rows.\n\n# Extract the results\nres <- as.data.frame(lrt$table)\n\nWe can now check out our results object, which will be a data.frame, a table.\n\n# Check out results object\nhead(res, 10)\n\n\n\n\n\n \n  \n      \n    logFC \n    logCPM \n    LR \n    PValue \n  \n \n\n  \n    ENSG00000182888 \n    -0.7030535 \n    -0.9936256 \n    4.2525633 \n    0.0391911 \n  \n  \n    ENSG00000286431 \n    1.5461179 \n    -0.1530747 \n    11.8110610 \n    0.0005888 \n  \n  \n    ENSG00000101846 \n    0.2581339 \n    1.7994127 \n    1.9918449 \n    0.1581481 \n  \n  \n    ENSG00000285679 \n    0.0118590 \n    -1.7883345 \n    0.0007381 \n    0.9783257 \n  \n  \n    ENSG00000101849 \n    0.1295766 \n    6.2607280 \n    1.2854701 \n    0.2568844 \n  \n  \n    ENSG00000047644 \n    0.4654929 \n    6.7504933 \n    14.5868099 \n    0.0001338 \n  \n  \n    ENSG00000004961 \n    -0.6228863 \n    3.7283726 \n    23.4757372 \n    0.0000013 \n  \n  \n    ENSG00000005302 \n    1.0203073 \n    6.7934565 \n    67.0298287 \n    0.0000000 \n  \n  \n    ENSG00000101911 \n    -0.8501682 \n    4.8448978 \n    55.9050804 \n    0.0000000 \n  \n  \n    ENSG00000229083 \n    -1.4635875 \n    0.8512208 \n    10.3340205 \n    0.0013060 \n  \n\n\n\n\n\nWe can additionally print out a summary of the results of the differential analysis at a P-value < 0.05 by using the following code:\n\nsummary(decideTests(lrt))\n\n       sample_groupTex\nDown              7046\nNotSig            8714\nUp                6923\n\n\nIn here we can see the type of comparison we are performing (vs the reference, in our case CD8+ Teff cells), the P-value threshold we used and the number of up-regulated and down-regulated genes at varying log-fold change levels, keep in mind that a log-fold change of 1 corresponds to a difference in raw gene expression value of 2 times since the log has a base of 2. So, to recap, all of the genes with log-fold change of 1 or more are twice as expressed in one condition compared to the other and we will later filter genes based on the fold-change value.\n\n\nSaving Results\nLet’s save the results object we just generated in a .csv file. We can then source it back and load it into the session using the code we have seen at the end of the first day of the workshop.\n\n# Save the results object\nwrite.table(res, \"results.csv\", sep=\",\", quote = F)\n\nIn the code below, we will create two new tables with the genes that were up-regulated and down-regulated in the comparison we performed, we will use these later.\n\n# Extract the information related to up-regulated and down-regulated genes\nup_df <- res %>% as.data.frame() %>% filter(PValue < 0.05 & logFC > 1)\ndown_df <- res %>% as.data.frame() %>% filter(PValue < 0.05 & logFC < -1)\n\nIf we check the table with the up-regulated genes we can see it has the following structure (we just took some specific rows - genes - of the complete results table corresponding to up-regulated genes):\n\nhead(up_df, 4)\n\n\n\n\n\n \n  \n      \n    logFC \n    logCPM \n    LR \n    PValue \n  \n \n\n  \n    ENSG00000286431 \n    1.546118 \n    -0.1530747 \n    11.811061 \n    0.0005888 \n  \n  \n    ENSG00000005302 \n    1.020307 \n    6.7934565 \n    67.029829 \n    0.0000000 \n  \n  \n    ENSG00000176896 \n    1.483553 \n    2.7280733 \n    49.397968 \n    0.0000000 \n  \n  \n    ENSG00000289449 \n    1.587543 \n    -1.3504361 \n    6.001932 \n    0.0142902 \n  \n\n\n\n\n\n\n💡 How would you check if the dimensions of the tables we extracted correspond to the number of differentially expressed genes present in the summary we printed above? (hint: go back and look at how we checked for the number of rows and columns in a table)\n\n\n\nVisualizing Results With MD Plots\nMD plots are used to get a sense of the proportions of up- and down-regulated genes between two conditions and the number of counts per million (CPM) of each gene, to check if genes with higher counts are statistically preferred to be also differential.\n\n# Plot the MD Plot\nplotMD(lrt)\nabline(h=c(-1, 1), col=\"gray\")\n\n\n\n\n\n\n\n\nWith the gray line we indicate a fold-change of +/- 1 which, if you recall, stands for an actual magnitude of change of value 2.\n\n\nVisualizing Results With Volcano Plots\nOnce we have our results from the comparison, we might want to present them graphically to aid their interpretation by other people or to emphasize messages of interest within them (like the statistics only for some genes of interest). One way to visualize results from a differential expression analysis is to draw a volcano plot. The goal of a volcano plot is to display and summarize the main metrics of output from a differential expression analysis, these consist of P-values and log-fold changes associated with each gene in the dataset for the specific comparison we are performing (Tex vs Teff in our case). These two variables can be plotted together to get a feel for the overall results in the analysis. Let’s plot a volcano summarizing the results of the comparison we have performed.\n\nlibrary(tidyr)\n\n# Set the threshold just for visualization!\nlog2FC_val = 1\npadj_val = 0.05\n\n# Create a table with gene information\nvolcano_corr = as.data.frame(res) %>% mutate(names=rownames(res)) %>% drop_na()\n\n# Create a separate column in the table with the information needed to color point in three categories\nvolcano_corr$threshold=ifelse(volcano_corr$logFC >= log2FC_val & volcano_corr$PValue < padj_val,\"A\",\n                         ifelse(volcano_corr$logFC <= -log2FC_val & volcano_corr$PValue < padj_val, \"B\",\"C\"))\n\n# Plot!\nggplot(volcano_corr, aes(x=logFC, y =-log10(PValue), color=threshold)) +\n    geom_point(alpha=0.9, size=3) +\n    scale_color_manual(values=c( \"B\"=\"#3891A6\",\"A\"=\"#C52233\", \"C\"=\"grey\")) + \n    xlab(\"log2(Fold Change)\") + ylab(\"-log10(adj p-value)\") +\n    theme_minimal() +\n    geom_vline(xintercept=0, color='black') +\n    geom_hline(yintercept=0, color='black') +\n    theme(legend.position=\"none\", axis.title.x = element_text(size = 17),\n                axis.text.y=element_text(size = 0),\n                axis.text.x=element_text(size = 17),\n               axis.title.y = element_text(size = 15)) \n\n\n\n\n\n\n\n\n\n\nMapping IDs to Gene Symbols\nThe volcano plot above is nice but it is not so informative since we cannot see any gene name! Unfortunately we do not have recognizable gene names in the res object, as we can see below:\n\n# In this case gene names are the names of the rows of our table\nrownames(res)[1:20]\n\n [1] \"ENSG00000182888\" \"ENSG00000286431\" \"ENSG00000101846\" \"ENSG00000285679\"\n [5] \"ENSG00000101849\" \"ENSG00000047644\" \"ENSG00000004961\" \"ENSG00000005302\"\n [9] \"ENSG00000101911\" \"ENSG00000229083\" \"ENSG00000205542\" \"ENSG00000261030\"\n[13] \"ENSG00000226985\" \"ENSG00000198759\" \"ENSG00000176896\" \"ENSG00000123595\"\n[17] \"ENSG00000046651\" \"ENSG00000289449\" \"ENSG00000233247\" \"ENSG00000130150\"\n\n\nWe can see that we currently have Ensembl Gene IDs as opposed to gene symbols! We can fix this by converting between the two, this can be achieved in R through dedicated packages like org.Hs.eg.db which map between the two types of gene identifiers. Let’s do it using the code below.\n\n# Use the package for the conversion between Ensembl IDs and Gene Symbols\nlibrary(org.Hs.eg.db)\n\nvolcano_corr$gene_names <- mapIds(org.Hs.eg.db, keys=row.names(volcano_corr), column=\"SYMBOL\", keytype=\"ENSEMBL\", multiVals=\"first\")\n\nWe can check that we now have new mapped gene symbols that we can use to make our volcano plot informative!\n\nvolcano_corr$gene_names[1:40] \n\n [1] \"RPS27AP20\"    NA             \"STS\"          NA             \"TBL1X\"       \n [6] \"WWC3\"         \"HCCS\"         \"MSL3\"         \"PRPS2\"        NA            \n[11] \"TMSB4X\"       NA             \"LINC01203\"    \"EGFL6\"        \"TCEANC\"      \n[16] \"RAB9A\"        \"OFD1\"         NA             NA             \"MOSPD2\"      \n[21] \"CA5BP1\"       \"CA5B\"         \"ZRSR2\"        NA             \"SYAP1\"       \n[26] \"TXLNG\"        \"NHS\"          \"SCML1\"        \"CDKL5\"        NA            \n[31] \"LOC101928415\" \"PDHA1\"        \"CNKSR2\"       \"MBTPS2\"       \"YY2\"         \n[36] \"SMS\"          \"PHEX\"         NA             \"PRDX4\"        \"SAT1\"        \n\n\nAnd finally we can try to plot again our volcano with the addition of gene names!\n\n\nShow code\nlibrary(ggrepel)\n\nvolcano_corr <- volcano_corr[order(volcano_corr$PValue, decreasing = FALSE),] %>% drop_na()\n\nnames_list <- c(volcano_corr$gene_names[1:10], \"TOX\", \"ENTPD1\", \"HAVCR2\")\n\nneg_fc <- volcano_corr[order(volcano_corr$logFC, decreasing = TRUE),] %>% filter(PValue < 0.05 ) %>% .$gene_names %>% head(10) # Change these numbers to avoid overcrowding in the plot\npos_fc <- volcano_corr[order(volcano_corr$logFC, decreasing = FALSE),] %>% filter(PValue < 0.05) %>% .$gene_names %>% head(10)\n\nnames_list <- c(names_list, neg_fc, pos_fc)\n  \nvolcano_corr <- volcano_corr %>% mutate(., stroke = ifelse(.$gene_names %in% names_list & volcano_corr$PValue < padj_val & volcano_corr$logFC > log2FC_val, 2, 0), \n                                               names=ifelse(.$gene_names %in% names_list,'mark','leave')) %>%\n                                                    .[order(.$names),]\n\nggplot(volcano_corr, aes(x=logFC, y =-log10(PValue), color=threshold)) +\n    geom_point(alpha=0.9, size=3) +\n    scale_color_manual(values=c( \"B\"=\"#3891A6\",\"A\"=\"#C52233\", \"C\"=\"grey\")) + \n    xlab(\"log2(Fold Change)\") + ylab(\"-log10(adj p-value)\") +\n    theme_minimal() +\n    geom_vline(xintercept=0, color='black') +\n    geom_hline(yintercept=0, color='black') +\n    theme(legend.position=\"none\", axis.title.x = element_text(size = 17),\n                axis.text.y=element_text(size = 0),\n                axis.text.x=element_text(size = 17),\n               axis.title.y = element_text(size = 15)) +\n    geom_label_repel(data=volcano_corr[which(volcano_corr$names=='mark' & volcano_corr$threshold=='A'),], aes(label=gene_names), max.overlaps = 30, color='black', size=4, fill='white', fontface='italic') +\n    geom_label_repel(data=volcano_corr[which(volcano_corr$names=='mark' & volcano_corr$threshold=='B'),], aes(label=gene_names), max.overlaps = 30, color='black', size=4, fill='white', fontface='italic')\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Results With Heatmaps\nWe can also plot differentially expressed genes in the two conditions of our interest using heatmaps. In this case we select genes based on their significance and visualize how their expression values change across samples just like we have done earlier.\n\n# Select conditions to plot, since we are plotting differentially expressed genes, we need to select the two categories in the comparison\nconds <- c(\"Tex\",\"Teff\")\n\n# Take genes\ndiffs <- rbind(volcano_corr[volcano_corr$threshold == \"A\",], volcano_corr[volcano_corr$threshold == \"B\",])$gene_names\n\n# Extract counts from `dds` object\nmtx <- cpm(dds)[,rownames(samples[which(samples$SampleGroup %in% conds),])]\n\n# Subset for differential genes \nids <- rownames(volcano_corr[which(volcano_corr$gene_names %in% diffs),])\n\n# Subset matrix for genes of interest\nmtx <- mtx[ids,]\n\n# Create another table for annotating the heatmap with colors\ndf <- as.data.frame(samples[,c(\"Donor\",\"SampleGroup\")])\n\n# Plot with pheatmap\npheatmap(mtx, cluster_rows=TRUE, show_rownames=FALSE,\n         cluster_cols=TRUE, annotation_col=df[which(rownames(df) %in% colnames(mtx)),], scale = \"row\")\n\n\n\n\n\n\n\n\nGiven that the number of differentially expressed genes can sometimes be very high, we cannot pretend to explore them manually one by one understanding their function! As we will see, there are further downstream analyses we can perform to get a sense of trends and pathways activated in the cell type of our interest. These analyses which look at genes in groups or ontologies try to match conditions with functions, to better elucidate what is going on inside cells in a specific condition.\n\n\nPlot single genes across samples\nHere we can plot the expression values of single genes to directly inspect the results of the differential gene expression analysis. Since we are dealing with multiple samples for which a measurement of gene expression has been performed, we are plotting each sample colored by its original category to understand the trends that we detect from the global differential gene expression analysis!\n\n# Select a set of genes to plot\ngnames_to_plot <- c(\"CD8A\", # Should not differ\n                    \"TOX\", # Previously associated with T cell exhaustion\n                    \"GNLY\", # Previously associated to T effector function\n                    \"IL7R\" # Previously associated to T memory function\n                    ) \n\n# Plot as a grouped boxplot with jittering\npldf <- cpm(dds, log=TRUE)[rownames(volcano_corr[which(volcano_corr$gene_names %in% gnames_to_plot),]),] %>% t() %>% as.data.frame() \ncolnames(pldf) <- gnames_to_plot\npldf %>% merge(samples, by=0) %>% \n            reshape2::melt() %>% \n            ggplot(., aes(x=SampleGroup, y=value)) + \n            geom_boxplot(fill=\"lightgray\") + \n            geom_jitter(aes(color=SampleGroup), size=3, alpha=0.7) +\n            scale_color_brewer(palette = 'RdYlBu') + \n            facet_wrap(~variable) + \n            theme_minimal()\n\n\n\n\n\n\n\n\n\n💡 Can we check the expression of one of the genes highlighted in the conclusions of the original paper?\n\n\n🤔 What if we want to plot the two most differentially expressed genes in both directions (both up and down)? hint: catch their names from the volcano_corr table by ordering it on fold-change with the %>% arrange() function"
  },
  {
    "objectID": "pages/day3.html#further-downstream-analyses",
    "href": "pages/day3.html#further-downstream-analyses",
    "title": "Day 3",
    "section": "Further Downstream Analyses",
    "text": "Further Downstream Analyses\nOnce we have our differentially expressed genes, we can perform various downstream analyses to check the functional aspects of the group of genes which are up- or down-regulated in our condition of interest. In the following sections, we will go through two of these, Gene Set Enrichment Analysis (GSEA) and Gene Ontology Enrichment Analysis (GO).\n\nGSEA\nGene Set Enrichment Analaysis was first published in 2005 as a method to interpret genome-wide expression profiles from RNA-seq data using sets of genes with known biological functions. In this sense, GSEA is used to check at which level a signature of genes is enriched in an expression profile. We can graphically summarize the steps in GSEA using the following picture, from the original publication.\n\n\nGSEA needs two ingredients, a ranked gene list from our analysis (for instance genes ordered by log-fold change) and a list of genes with biological relevance (for instance genes known to regulate CD8+ T-cell exhaustion).\n\n1. We start by taking our list of up- or down- regulated genes and order them based on the value of their fold-change so that our list will have genes that change a lot positively at the top and ones that change a lot negatively at the bottom. This will represent our ranking.\n2. We then take one or more curated and archived gene sets which are related to a biological function we might be interested in investigating in our dataset.\n3. Finally we go through our ranking from top to bottom counting the number of times we see a gene which is also in the gene set that we are looking at. We expect to see genes from a given gene set appear at the top of our ranking if that biological function is particularly important in the genes of our ranking.\nOver the years, a collection of curated gene sets called MSigDB has been expanded and is now a great resource to check which ones are more or less enriched in our data at hand.\n\n\nThe web interface for the MSigDB gene set database\n\nIn our specific use case, we are going to run GSEA on the set of up-regulated genes in CD8+ Tex cells to check if a gene set of exhaustion is indeed enriched in the genes we have found up-regulated. For this task we are going to use the fgsea package. In order to extract the gene set without the need to directly download it, we are going to access MSigDB directly from R using another package called msigdbr.\n\n🚨 WARNING: This code that follows might kill your R session inadvertedly. If this happens, don’t panic, and reload the object we saved before! Use the following syntax to get back on track after you resume the session:\n res <- read.table(\"results.csv\", sep = \",\")\n samples <- read.table(\"samples_table.csv\", sep = \",\")\nIn this way you should be all set to successfully run all the code below! 🙌🏻\n\n\nExtract MSigDB Signatures\nIn the following chunk, we use a function from the msigdbr package to extract the gene set of our interest:\n\nlibrary(msigdbr)\n\n# Extract the gene sets from the MSigDB database\nimmune_gsets <- msigdbr(species = \"human\", category = \"C7\", subcategory = \"IMMUNESIGDB\")\n\nLet’s see what’s in the immune_gsets object:\n\n# Take a look at what we fetched from the database\nhead(immune_gsets, 5)\n\n\n\n\n\n \n  \n    gs_cat \n    gs_subcat \n    gs_name \n    gene_symbol \n    entrez_gene \n    ensembl_gene \n    human_gene_symbol \n    human_entrez_gene \n    human_ensembl_gene \n    gs_id \n    gs_pmid \n    gs_geoid \n    gs_exact_source \n    gs_url \n    gs_description \n  \n \n\n  \n    C7 \n    IMMUNESIGDB \n    GOLDRATH_EFF_VS_MEMORY_CD8_TCELL_DN \n    ABCA2 \n    20 \n    ENSG00000107331 \n    ABCA2 \n    20 \n    ENSG00000107331 \n    M3044 \n    16492737 \n     \n    GSE1000002_1582_200_DN \n     \n    Genes down-regulated in comparison of effector CD8 T cells versus memory CD8 T cells. \n  \n  \n    C7 \n    IMMUNESIGDB \n    GOLDRATH_EFF_VS_MEMORY_CD8_TCELL_DN \n    ABCC5 \n    10057 \n    ENSG00000114770 \n    ABCC5 \n    10057 \n    ENSG00000114770 \n    M3044 \n    16492737 \n     \n    GSE1000002_1582_200_DN \n     \n    Genes down-regulated in comparison of effector CD8 T cells versus memory CD8 T cells. \n  \n  \n    C7 \n    IMMUNESIGDB \n    GOLDRATH_EFF_VS_MEMORY_CD8_TCELL_DN \n    ABHD14A \n    25864 \n    ENSG00000248487 \n    ABHD14A \n    25864 \n    ENSG00000248487 \n    M3044 \n    16492737 \n     \n    GSE1000002_1582_200_DN \n     \n    Genes down-regulated in comparison of effector CD8 T cells versus memory CD8 T cells. \n  \n\n\n\n\n\nWe can see that every row is a different gene (the gene_symbol colums) with its associated gene set (gs_name column). We will now extract a gene set related to CD8+ T-cell exhaustion which comes from this publication and is names GSE9650_EFFECTOR_VS_EXHAUSTED_CD8_TCELL_DN in the database.\n\n# Filter the `immune_gsets` table and take only the genes from the gene set of our interest\ngene_set_name <- \"GSE9650_EFFECTOR_VS_EXHAUSTED_CD8_TCELL_DN\"\ntex_sig_df <- immune_gsets %>% filter(gs_name == gene_set_name)\n\nHow many genes do we have in the gene set that we just isolated? We can check this by looking at the number of rows of this new tex_sig_df table that we generated above using the command nrow(tex_sig_df). Doing this should result in having 232 genes.\n\n\nPerform GSEA\nNow we can perform GSEA using the fgsea package in R!\n\nlibrary(fgsea)\n\n# Prepare the ranking based on fold-change, from high (expressed in Tex) to low (expressed in Teff)\nids <- res %>% arrange(desc(logFC)) %>% rownames()\nvals <- res %>% arrange(desc(logFC)) %>% pull(logFC)\n\n# Set names\nnames(vals) <- ids \n\n# Prepare gene set\ngset <- list(tex_sig_df$ensembl_gene)\nnames(gset) <- gene_set_name\n\n# Run GSEA\nfgseaRes <- fgsea(pathways = gset, \n                  stats    = vals,\n                  eps      = 0.0)\n\n\n# Take a look at results\nfgseaRes\n\n\n\n\n\n \n  \n    pathway \n    pval \n    padj \n    log2err \n    ES \n    NES \n    size \n    leadingEdge \n  \n \n\n  \n    GSE9650_EFFECTOR_VS_EXHAUSTED_CD8_TCELL_DN \n    6.66e-05 \n    6.66e-05 \n    0.5384341 \n    -0.4233808 \n    -1.759835 \n    144 \n    ENSG00000205002, ENSG00000143333, ENSG00000115008, ENSG00000164251, ENSG00000151012, ENSG00000198369, ENSG00000100285, ENSG00000122877, ENSG00000186827, ENSG00000172301, ENSG00000168209, ENSG00000049249, ENSG00000134202, ENSG00000067208, ENSG00000122378, ENSG00000162692, ENSG00000144935, ENSG00000139318, ENSG00000022267, ENSG00000005189, ENSG00000183814, ENSG00000186187, ENSG00000153234, ENSG00000174500, ENSG00000178695, ENSG00000147383, ENSG00000120699, ENSG00000132326, ENSG00000126778, ENSG00000174307, ENSG00000142453, ENSG00000148834, ENSG00000111142, ENSG00000177425, ENSG00000162775, ENSG00000181019, ENSG00000174437, ENSG00000122140, ENSG00000000971, ENSG00000117595, ENSG00000106546, ENSG00000168298, ENSG00000132305, ENSG00000241468, ENSG00000196388, ENSG00000100473, ENSG00000128791 \n  \n\n\n\n\n\nWe can now plot the GSEA results in the standard way:\n\n# Plot GSEA results\nplotEnrichment(gset[[gene_set_name]],\n               vals) + labs(title=gene_set_name)\n\n\n\n\n\n\n\n\nFrom the GSEA results, we can see that the current gene set we used is mostly depleted in the differential genes we have in our CD8+ Tex vs CD8+ Teff comparison. Given that the gene set comes from a study carried out in mice in a context of chronic viral infection, this might indicate that our current results reflect a different kind of CD8+ T-cell exhaustion observed in the tumor microenvironment of human tumors as opposed to the process happening during viral infection in mice.\n\n💡 Whenever we use gene sets when testing for enrichment, we have to be sure of where they were isolated in order to avoid misinterpreting results and/or getting to wrong conclusions, like it could have happened in this case!\n\n\n\n\nGene Ontology Enrichment Analysis\nNext, we will try to get a more unsupervised look at what kind of biology is happening inside our CD8+ Tex cells by performing a Gene Ontology Enrichment analysis. This will allow us to check which and how many up-regulated genes in CD8+ Tex cells are represented in various biological processes. We will do this using the clusterProfiler package in R.\n\nlibrary(clusterProfiler)\n\n# Get up-regulated genes\ngenes <- rownames(up_df)\n\n# Perform gene ontology enrichment\nego <- enrichGO(gene         = genes,\n                OrgDb         = org.Hs.eg.db,\n                keyType       = 'ENSEMBL',\n                ont           = \"MF\", # Molecular Function, use \"BP\" or \"CC\" for Biological Process or Cellular Component\n                pAdjustMethod = \"BH\",\n                pvalueCutoff  = 0.05,\n                qvalueCutoff  = 0.05,\n                readable      = TRUE)\n\n\nhead(ego)\n\n\n\n\n\n \n  \n      \n    ID \n    Description \n    GeneRatio \n    BgRatio \n    pvalue \n    p.adjust \n    qvalue \n    geneID \n    Count \n  \n \n\n  \n    GO:0019957 \n    GO:0019957 \n    C-C chemokine binding \n    10/1394 \n    24/20616 \n    1.60e-06 \n    0.0012476 \n    0.0011809 \n    CXCR3/CCR8/CXCR6/CCR3/CCR2/CCR5/CX3CR1/XCR1/CXCR1/ZFP36 \n    10 \n  \n  \n    GO:0001637 \n    GO:0001637 \n    G protein-coupled chemoattractant receptor activity \n    10/1394 \n    26/20616 \n    3.80e-06 \n    0.0012476 \n    0.0011809 \n    CXCR3/CCR8/CXCR6/CCR3/CCR2/CCR5/CX3CR1/XCR1/CMKLR1/CXCR1 \n    10 \n  \n  \n    GO:0004950 \n    GO:0004950 \n    chemokine receptor activity \n    10/1394 \n    26/20616 \n    3.80e-06 \n    0.0012476 \n    0.0011809 \n    CXCR3/CCR8/CXCR6/CCR3/CCR2/CCR5/CX3CR1/XCR1/CMKLR1/CXCR1 \n    10 \n  \n  \n    GO:0019956 \n    GO:0019956 \n    chemokine binding \n    11/1394 \n    33/20616 \n    6.30e-06 \n    0.0015561 \n    0.0014729 \n    CXCR3/CCR8/CXCR6/CCR3/CCR2/CCR5/CX3CR1/XCR1/ITGA4/CXCR1/ZFP36 \n    11 \n  \n  \n    GO:0016493 \n    GO:0016493 \n    C-C chemokine receptor activity \n    9/1394 \n    23/20616 \n    9.90e-06 \n    0.0019595 \n    0.0018547 \n    CXCR3/CCR8/CXCR6/CCR3/CCR2/CCR5/CX3CR1/XCR1/CXCR1 \n    9 \n  \n  \n    GO:0140326 \n    GO:0140326 \n    ATPase-coupled intramembrane lipid transporter activity \n    6/1394 \n    11/20616 \n    3.25e-05 \n    0.0053729 \n    0.0050856 \n    ABCB4/ABCB1/ABCA7/ABCA1/ABCA2/ATP8A2 \n    6 \n  \n\n\n\n\n\nLet’s now plot the enrichment values that we got with a graph layout.\n\n# Plot results of gene ontology enrichment\ngoplot(ego, firstSigNodes=10)\n\n\n\n\n\n\n\n\nNow we can also plot the results with what is known as a ranked dot plot, here we encode the significance of the enrichment in the color of the dot, while its size represent the overlap of the specific gene set with the one we are using to perform the test (our list of up-regulated genes).\n\ndotplot(ego, showCategory=20) + ggtitle(\"Dotplot for GO enrichment\")\n\n\n\n\n\n\n\n\n\n💡 GO analyses might highlight very interesting patterns and generate hypotheses, but are many times quite hard to interpret depending also on the biological system we are studying."
  },
  {
    "objectID": "pages/day2.html",
    "href": "pages/day2.html",
    "title": "Day 2",
    "section": "",
    "text": "Learn about data normalization\nLearn about the edgeR package\nExplore different normalization methods\nNormalize the data with functions provided by the edgeR package\nPerform diagnostic and exploratory analysis on the data"
  },
  {
    "objectID": "pages/day2.html#why-do-we-need-it",
    "href": "pages/day2.html#why-do-we-need-it",
    "title": "Day 2",
    "section": "Why Do We Need It?",
    "text": "Why Do We Need It?\nNormalization is the process by which we try to conform count data to make it comparable across samples and even across different genes. This is done to ensure that all of the uninteresting differences between genes are minimized in favor of the interesting biological differences that we want to highlight.\nThe main factors to take into account when normalizing data are:\n\nSequencing Depth:\n\n\n\nDifferences in sequencing depth (total number of reads in a sample) can cause genes to appear differentially expressed just due to technical reasons.\n\n\nGene Length:\n\n\n\nDifferences in gene length means that longer genes are prone to have more reads coming from them, therefore we need to normalize also for this aspect while processing data.\n\n\nRNA Composition:\n\n\n\nDifferences in RNA composition are also causative of technical artefacts which can skew the analyses. Differences in the number of genes expressed between samples and the number of differentially expressed gene across samples can greatly and negatively impact normalization methods. In the example, the majority of counts for sample A is related to the DE gene and therefore this might cause other genes to be normalized by this high number of counts, resulting in them appearing to be expressed at a lower level as opposed to the same genes in sample B."
  },
  {
    "objectID": "pages/day2.html#normalization-strategies",
    "href": "pages/day2.html#normalization-strategies",
    "title": "Day 2",
    "section": "Normalization Strategies",
    "text": "Normalization Strategies\nDuring the years, many approaches to data normalization have been attempted and are summarized in the table below. You can see that they try to tackle each one of the issues we highlighted above.\n\n\n\nNormalization Method\nAccounted Factors\nDescription\n\n\n\n\nCPM (counts per million)\nSequencing depth\nCounts scaled by total read number\n\n\nTPM (transcripts per million)\nSequencing depth and gene length\nCounts per length of transcript (kb) per million mapped reads\n\n\nFPKM/RPKM\nSequencing depth and gene length\nCounts per kilobase of exon mapped reads per million mapped reads\n\n\nDESeq2’s median of ratios1\nSequencing depth and RNA composition\nCounts are divided by a sample-specific size factor\n\n\nedgeR’s trimmed mean of M values2\nSequencing depth, RNA composition and gene length\nWeighted trimmed mean of the log ratio of expression between samples\n\n\n\nOut of all these, we will use one of the more advanced ones provided in the edgeR package which will be now introduced."
  },
  {
    "objectID": "pages/day2.html#introduction",
    "href": "pages/day2.html#introduction",
    "title": "Day 2",
    "section": "Introduction",
    "text": "Introduction\nOne of the main interests behind performing a bulk RNA experiment is understanding which genes are more or less expressed across a set of conditions of interest, so we will compare gene expression levels and statistically assess and quantify differences arising between the conditions represented by our categories of samples. In this section we will start getting a feel for what the edgeR package is and how to use it to perform normalization and differential expression analysis on our bulk RNA seq data.\n\n💡 Detailed explanations of the statistical procedures implemented in the package are available in the package’s vignette.\n\nWe will start by loading the package that we installed in yesterday’s initial “setup” section:\n\n# Load the package\nlibrary(edgeR)\n\nThe package contains many functions which are very helpful when dealing with tables of count data, we can inspect them all by typing the following command:\n\n# This should open a popup window in the lower right part of the screen displaying the functions in the package\n??edgeR\n\nIn the sections below, we will follow the standard analysis workflow suggested by the edgeR developers."
  },
  {
    "objectID": "pages/day2.html#create-a-dgelist-object",
    "href": "pages/day2.html#create-a-dgelist-object",
    "title": "Day 2",
    "section": "Create a DGEList object",
    "text": "Create a DGEList object\nIn order for the package to read and understand our data and correctly perform the analysis, we need to organize our data in a way that the functions of the package can handle. This new object that we are going to create is called DGEList and there is a utility function to create one starting from the ingredients we currently have, (1) a table of counts (our counts object), (2) a table with sample information (our samples object). and (3) one last thing that we need to decide in order tell the package what comparisons we value the most, this is called a design formula.\n\nBehind The Design Formula\nThe design formula should contain the name of a column of interest in our table of samples which stores the information related to the levels (or categories) we want to contrast. Let’s say that we have a dataset with two conditions (condition_1 vs condition_2) that we want to compare. The samples table will look like this, with three replicates for each of the two conditions:\n\n\n\nSample Code\nPatient\nCondition\n\n\n\n\nSA1\nPt1\nCondition_1\n\n\nSA2\nPt2\nCondition_1\n\n\nSA3\nPt3\nCondition_1\n\n\nSA4\nPt1\nCondition_2\n\n\nSA5\nPt2\nCondition_2\n\n\nSA6\nPt3\nCondition_2\n\n\n\n\nPaired Analyses\nThe optimal setting for the analysis (decided experimentally) is to have paired samples. This might be a somewhat difficult concept to grasp, but for our table above this means that every Patient contributes equally to the two categories in the Condition columns that we are interested in. In this setting, we are fully capable of exploiting the statistics behind the tools we use for differential analysis by correcting for the uninteresting differences arising between patients. This aspect greatly helps the analysis and improves the statistical validity of the results.\n\n💡 Remember, this is something achieved by deciding the experimental setting beforehand! Ideally this should be done through a collaborative effort between bioinformaticians/statisticians and bench scientists!\n\n\nIf we are interested in performing a differential expression analysis comparing condition_1 versus condition_2, then our design formula should specify the Condition column.\n\n💡 What is the column that we are interested in when specifying the design formula using in our samples table?\n\nNow that we also understand the design formula, we can create the DGEList object with the data that we loaded beforehand, but first we need to check that the columns of the counts table are in the same order of the rows of the sample table, this is important since we want to be sure that the right levels of expression are associated to the right sample.\n\nall(rownames(samples) == colnames(counts))\n\n[1] TRUE\n\n\nNow that we are sure about this aspect we can actually build the object:\n\n# Create a design formula\ndonor <- samples$Donor\nsample_group <- factor(samples$SampleGroup, levels=c(\"Teff\",\"Trest\",\"Ttumor\",\"Tex\")) # Teff becomes our \"control\" group to which we compare the others\n\ndesign <- model.matrix(~ donor + sample_group)\n\n# Create a `DGEList` object and call it dds\ndds <- DGEList(counts = counts, \n                samples = samples \n                    )\n\n# Let's save the `design` in the dds object (remeber that `dds` is just a list in R which can be updated with different elements)\ndds$design <- design\n\nWe can now remove the counts table from our R environment since that information is stored in our DGEList object now. This is useful to save on memory space!\n\n# Remove original `counts` table to save memory space\nrm(counts)\ngc()\n\nGreat! You have created a DGEList object which we called dds, this contains all the information related to the counts table and the sample information table in one spot. We can have a look at the sample information table and the counts table in the dds object like so:\n\n# Look at the table with sample information\nhead(dds$samples)\n\n\n\n\n\n \n  \n      \n    group \n    lib.size \n    norm.factors \n    Donor \n    SampleGroup \n    sex \n  \n \n\n  \n    BSSE_QGF_204446 \n    1 \n    40969678 \n    1 \n    HD276 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204447 \n    1 \n    38734896 \n    1 \n    HD276 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204448 \n    1 \n    57149808 \n    1 \n    HD276 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204449 \n    1 \n    45415276 \n    1 \n    HD276 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204450 \n    1 \n    51767738 \n    1 \n    HD280 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204451 \n    1 \n    49277273 \n    1 \n    HD280 \n    Ttumor \n    Male \n  \n\n\n\n\n\nWe can see that some new columns were added to the samples table present in our DGEList object when we created it (the group, lib.size, norm.factors columns)! These will be used by edgeR later on for data normalization!\nWe can also take a look at the table containing the counts, which is just another element of our DGEList object:\n\n# Look at the table with count information\nhead(dds$counts)\n\n\n\n\n\n \n  \n      \n    BSSE_QGF_204446 \n    BSSE_QGF_204447 \n    BSSE_QGF_204448 \n    BSSE_QGF_204449 \n    BSSE_QGF_204450 \n    BSSE_QGF_204451 \n    BSSE_QGF_204452 \n    BSSE_QGF_204453 \n    BSSE_QGF_204458 \n    BSSE_QGF_204459 \n    BSSE_QGF_204460 \n    BSSE_QGF_204461 \n    BSSE_QGF_204462 \n    BSSE_QGF_204463 \n    BSSE_QGF_204464 \n    BSSE_QGF_204465 \n  \n \n\n  \n    ENSG00000228572 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000182378 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000226179 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000281849 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000280767 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000185960 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0"
  },
  {
    "objectID": "pages/day2.html#filtering-genes",
    "href": "pages/day2.html#filtering-genes",
    "title": "Day 2",
    "section": "Filtering genes",
    "text": "Filtering genes\nWe can the inspect the size of our dds object to check how many genes and samples we have, you can see that this mirrors exactly the counts table that we had previously, before incorporating it into the object.\n\ndim(dds$counts)\n\n[1] 62854    16\n\n\n\n💡 In R, list elements are accessible with the $ accessor. Our dds object is indeed a list made up of three elements, the counts table, the samples table and the design table, these are accessible using $ like we did above.\n\nNow we can start removing some genes which are expressed at low levels. This action is justified both from the biological and the statistical points of view. Biologically, lowly expressed genes are less interesting while statistically, they do not provide enough sampling power to confidently test them for differential expression. In the following chunk we filter our dds object by keeping only genes (rows) which have at least 10 detected counts in each sample using the filterByExpr() function in the edgeR package.\n\n# Select which genes to keep\nkeep <- filterByExpr(dds, design)\n\n# Filter\ndds <- dds[keep, , keep.lib.sizes=FALSE]\n\n\n💡 This is somewhat of an “easy” filtering strategy, there are many more complex ones available but sometimes it’s best to keep things simple!\n\nLet’s check how many genes we’re left with after filtering:\n\ndim(dds$counts)\n\n[1] 22683    16\n\n\nYou can see that we have cut the number of genes in our dataset by more than half, now we have 22683 remaining genes."
  },
  {
    "objectID": "pages/day2.html#normalizing-count-data",
    "href": "pages/day2.html#normalizing-count-data",
    "title": "Day 2",
    "section": "Normalizing Count Data",
    "text": "Normalizing Count Data\nAs we have discussed above, normalization is an integral step to the downstream analysis of bulk RNA-seq data. In this section we will normalize our data using the calcNormFactors function of the package. As we have previously introduced, edgeR uses the trimmed mean of M-values (TMM) method to calculate a set of size factors to minimize the log-fold change differences occurring between samples (uninteresting) for the majority of genes. The counts for each sample get then multiplied by the scaling factors to generate what is referred to as effective library size, which will be used for all downstream analyses.\n\n# Call the function to normalize count data\ndds <- calcNormFactors(dds)\n\nWe can check the values of the computed size factors by doing the following, note how there are as many size factors as there are samples and they are inserted in a column of the samples table named norm.factors in our DGEList object:\n\ndds$samples\n\n\n\n\n\n \n  \n      \n    group \n    lib.size \n    norm.factors \n    Donor \n    SampleGroup \n    sex \n  \n \n\n  \n    BSSE_QGF_204446 \n    1 \n    40949757 \n    1.0306089 \n    HD276 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204447 \n    1 \n    38716755 \n    0.9957071 \n    HD276 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204448 \n    1 \n    57115716 \n    0.9261344 \n    HD276 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204449 \n    1 \n    45387259 \n    1.0424493 \n    HD276 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204450 \n    1 \n    51743863 \n    1.0199158 \n    HD280 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204451 \n    1 \n    49255461 \n    0.9724292 \n    HD280 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204452 \n    1 \n    50025518 \n    0.9978416 \n    HD280 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204453 \n    1 \n    47946651 \n    1.0157618 \n    HD280 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204458 \n    1 \n    39620524 \n    1.0178698 \n    HD286 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204459 \n    1 \n    39543464 \n    1.0039252 \n    HD286 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204460 \n    1 \n    36004615 \n    0.9694099 \n    HD286 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204461 \n    1 \n    36042139 \n    1.0006105 \n    HD286 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204462 \n    1 \n    40382246 \n    1.0352586 \n    HD287 \n    Trest \n    Female \n  \n  \n    BSSE_QGF_204463 \n    1 \n    48326105 \n    0.9682855 \n    HD287 \n    Ttumor \n    Female \n  \n  \n    BSSE_QGF_204464 \n    1 \n    52039214 \n    0.9942164 \n    HD287 \n    Teff \n    Female \n  \n  \n    BSSE_QGF_204465 \n    1 \n    44687575 \n    1.0164136 \n    HD287 \n    Tex \n    Female \n  \n\n\n\n\n\n\nVisualizing the relationshhip between library size and size factors\nWe can explore the relationship between the total library size for each of our samples and their respective norm.factors to understand what the purpose of the size factors is! Since we are going to use the factors balance differences of counts, we expect a positive relationship between the total number of counts in a sample and its estimated norm.factors.\n\n# Plot relationship\nlibrary(ggplot2)\n\ndds$samples %>% ggplot(.,aes(x = norm.factors, y = lib.size, color=SampleGroup)) + \n      geom_point(size=8, alpha=0.7)+\n      ggtitle(\"Relationship between Normalization Factors and Library Size\") + \n      theme_classic() +\n      theme(plot.title = element_text(hjust = 0.5)) \n\n\n\n\n\n\n\n\n\n💡 NOTE: Although edgeR does not use normalized counts as input (the normalization process happens inside automatically), the normalized counts we just generated are definitely useful when plotting results and performing clustering."
  },
  {
    "objectID": "pages/day2.html#transforming-count-data",
    "href": "pages/day2.html#transforming-count-data",
    "title": "Day 2",
    "section": "Transforming Count Data",
    "text": "Transforming Count Data\nAfter we have normalized our data, we need to perform a transformation. There are many ways to transform count data but all of them achieve the goal of removing the gene-wise dependence between variance and mean of expression values across samples (something called homoscedasticity) in order to highlight interesting and biologically relevant expression trends even for genes expressed at lower values. We transform the data using a function provided in the edgeR package called cpm() which also performs a logarithmic transformation which has the effect of reshaping the data to achieve gene-wise distributions which resemble a normal distribution. Without getting too much into the details of the workings of the function, we will transform the data and then look at how the gene-wise relationship between the mean and variance in our normalized data changes before and after the transformation. The purpose of this procedure is to allow proper data visualization later in the analysis, the transformed data is NOT used for the differential expression analysis which instead starts from raw counts!\nThe following code is used to plot the mean/standard deviation relationship of every gene before the transformation.\n\nlibrary(vsn)\n\n# Plot before data transformation\nmeanSdPlot(dds$counts)\n\n\n\n\n\n\n\n\nTransform the data and then plot the mean/standard deviation relationship after the transformation.\n\n# Transform the data with a log2 transform (watch how we create a new variable for it)\nlog2dds <- cpm(dds, log=TRUE)\n\n\n# Check out the transformed values (notice how we now have floating point values and some are even negative!)\nhead(log2dds)\n\n\n\n\n\n \n  \n      \n    BSSE_QGF_204446 \n    BSSE_QGF_204447 \n    BSSE_QGF_204448 \n    BSSE_QGF_204449 \n    BSSE_QGF_204450 \n    BSSE_QGF_204451 \n    BSSE_QGF_204452 \n    BSSE_QGF_204453 \n    BSSE_QGF_204458 \n    BSSE_QGF_204459 \n    BSSE_QGF_204460 \n    BSSE_QGF_204461 \n    BSSE_QGF_204462 \n    BSSE_QGF_204463 \n    BSSE_QGF_204464 \n    BSSE_QGF_204465 \n  \n \n\n  \n    ENSG00000182888 \n    -1.0149871 \n    -0.8276939 \n    -0.3549182 \n    -1.8514197 \n    -1.115602 \n    -1.6618073 \n    -0.8744661 \n    -1.5038016 \n    -0.2547841 \n    -1.0805284 \n    -0.8356222 \n    -1.6352550 \n    -1.0025724 \n    -1.0191401 \n    -1.0315768 \n    -0.8033451 \n  \n  \n    ENSG00000286431 \n    -0.5471054 \n    -0.1931254 \n    -2.4984815 \n    -0.1680466 \n    -1.239220 \n    0.3755188 \n    -1.4534058 \n    -0.3141114 \n    -0.7014695 \n    -0.2332744 \n    -2.4120935 \n    0.3700598 \n    0.4937172 \n    0.2613948 \n    0.5415924 \n    0.9045618 \n  \n  \n    ENSG00000101846 \n    2.1233683 \n    1.5858211 \n    1.4484255 \n    1.4028791 \n    1.843186 \n    1.1065503 \n    0.5128935 \n    1.2788434 \n    2.1960905 \n    1.5810286 \n    1.0755162 \n    1.6037361 \n    2.8425327 \n    2.3711547 \n    2.1097388 \n    2.0027201 \n  \n  \n    ENSG00000285679 \n    -2.0942552 \n    -2.5201103 \n    -0.9510723 \n    -0.7006700 \n    -3.975320 \n    -2.1045036 \n    -1.7128386 \n    -1.7807883 \n    -2.7977125 \n    -2.0224031 \n    -2.4120935 \n    -2.0665580 \n    -1.5921819 \n    -2.7227787 \n    -1.0897366 \n    -1.5028451 \n  \n  \n    ENSG00000101849 \n    6.2932846 \n    6.5684439 \n    5.7528313 \n    6.0670351 \n    6.313155 \n    6.7504778 \n    6.2718734 \n    6.4182406 \n    5.9469254 \n    6.2362473 \n    6.0449854 \n    6.0232538 \n    6.1471371 \n    6.5996337 \n    6.1418289 \n    6.2462658 \n  \n  \n    ENSG00000047644 \n    6.7095330 \n    6.8576121 \n    6.0848036 \n    6.7826289 \n    6.851492 \n    6.7861213 \n    6.6774144 \n    6.8849740 \n    6.8038382 \n    6.7468953 \n    6.6256517 \n    6.9155029 \n    6.7548269 \n    6.9650206 \n    6.2931482 \n    6.9985429 \n  \n  \n    ENSG00000004961 \n    3.8196064 \n    3.4514638 \n    4.0436716 \n    3.1400969 \n    3.981022 \n    3.5656781 \n    4.0153569 \n    3.5366299 \n    3.9137232 \n    3.5052341 \n    3.9041578 \n    3.4878931 \n    3.9178339 \n    3.6855962 \n    3.9833428 \n    3.2956981 \n  \n  \n    ENSG00000005302 \n    7.0462220 \n    7.0755388 \n    5.5725868 \n    6.7473035 \n    6.839845 \n    6.9951121 \n    5.8821984 \n    6.9665842 \n    6.8417578 \n    7.0615117 \n    5.8538203 \n    7.0057387 \n    7.1513026 \n    7.1233253 \n    6.3282750 \n    7.0236595 \n  \n  \n    ENSG00000101911 \n    4.7362798 \n    4.4243203 \n    5.3979519 \n    4.8293174 \n    4.468497 \n    4.1665467 \n    5.2938577 \n    4.1904009 \n    4.9056304 \n    4.5910118 \n    5.5054859 \n    4.7018879 \n    4.8114113 \n    4.4770266 \n    5.4725700 \n    4.5377748 \n  \n  \n    ENSG00000229083 \n    1.0417306 \n    -1.5995957 \n    1.8322453 \n    0.0241205 \n    0.955676 \n    0.0072169 \n    1.4054066 \n    0.7370180 \n    0.8912343 \n    0.4106746 \n    1.7146421 \n    0.7958171 \n    1.1040597 \n    -2.9421761 \n    1.7272985 \n    -0.3748886 \n  \n\n\n\n\n\n\n# let's plot the transformed values\nmeanSdPlot(log2dds)\n\n\n\n\n\n\n\n\n\n💡 It is clear how genes with high mean expression values (on the right) are now comparable in terms of standard deviation to genes with lower mean expression values (on the left)."
  },
  {
    "objectID": "pages/day2.html#data-quality-visual-assessment",
    "href": "pages/day2.html#data-quality-visual-assessment",
    "title": "Day 2",
    "section": "Data Quality Visual Assessment",
    "text": "Data Quality Visual Assessment\nOne way to understand trends in our data and the present of poor quality or outlier samples is to perform exploratory analyses through visualization. In R in general, data visualization is aided by the presence of many packages (on top the basic plotting functionality) which can handle diverse kinds of data visualization tasks (from traditional plots to visualizing tabular data through heatmaps). We will encounter two of these packages, one is ggplot2 and the other one is pheatmap.\n\nClustering\nOne of the main strategies for checking the consistency of our dataset is to cluster samples based on their complete expression profile (which as you might recall consists of 22683 genes in our dataset). This will allow us to spot the presence of outliers in the data and look for consistent profiles of gene expression across replicates, which we expect. Use the code below to plot a heatmap of normalized (and transformed) expression values for our samples. Since plotting the full expression table can be computationally expensive, we might want to subset it to the 400 top expressed genes in the dataset.\n\nlibrary(\"pheatmap\")\n\n# Take the top 200 genes in the dataset\nselect <- order(rowMeans(log2dds),\n                decreasing=TRUE)[1:400] # Select number of genes\n\n# Create another table for annotating the heatmap with colors\ndf <- as.data.frame(samples[,c(\"Donor\",\"SampleGroup\")])\n\n# Draw the heatmap using the `pheatmap` package\npheatmap(log2dds[select,], cluster_rows=FALSE, show_rownames=FALSE,\n         cluster_cols=TRUE, annotation_col=df)\n\n\n\n\n\n\n\n\n\n💡 What type of assessment would you make about the consistency of the samples across these top 400 genes? Do they cluster (a synonym for similar) based on the donor or on the biological condition of our interest?\n\n\n\nSample-to-sample Distances\nAnother way to get a sense of the global relationship between samples is to check for how distant samples are between themselves. This analysis of pairwise distances looks at the expression value of all 22683 genes in the dataset and determines which samples have a more or less similar or different expression value for each. We expect biologically similar samples to have very little difference.\n\nlibrary(RColorBrewer)\n\n# Compute distances\nsampleDists <- dist(t(log2dds))\n\n# Organize\nsampleDistMatrix <- as.matrix(sampleDists)\n\ncolors <- colorRampPalette( rev(brewer.pal(9, \"Blues\")) )(255)\n\n# Plot with `pheatmap`\npheatmap(sampleDistMatrix,\n         clustering_distance_rows=sampleDists,\n         clustering_distance_cols=sampleDists,\n         color = colors,\n         annotation_col = df)\n\n\n\n\n\n\n\n\n\n# Free up memory space\nrm(sampleDistMatrix)\ngc()\n\n\n💡 What type of assessment would you make about the heatmap you just produced? Which CD8 T-cell populations are mostly similar in terms of overall gene expression profile? Does a particular population stand out?\n\n\n\nPrincipal Component Analysis (PCA)\nAnother useful approach for understanding the main variability axes in our data is to compute and plot a PCA. Without getting into the details, PCA takes our expression data and outputs its principal components, which encode the main sources of variability in the data. Ideally, we want the samples to have variability caused by the biological effect of our interest (in this case the differences between CD8 T-cell populations), but this might not be the case. By plotting and coloring the points by different covariates (i.e. donor or cell type) we are able to understand where the variability comes from and if there is any detectable batch effect. Use the code below to generate a scatter plot of PCA coordinates and color them to understand what causes the variability in the data.\n\nlibrary(ggplot2)\n\n# Calculate principal components and percentage of variance\npcs <- prcomp(log2dds, scale = TRUE)\npercentVar <- round(100 * summary(pcs)$importance[2,])\npcaData <- as.data.frame(pcs$rotation) %>% merge(samples, by=0)\n\n# Plot (this time with ggplot2!!)\nggplot(pcaData, aes(PC1, PC2, color=SampleGroup, shape=Donor)) +\n  geom_point(size=3) +\n  xlab(paste0(\"PC1: \",percentVar[1],\"% variance\")) +\n  ylab(paste0(\"PC2: \",percentVar[2],\"% variance\")) + \n  theme_classic()\n\n\n\n\n\n\n\n\n\n💡 What can you say about this PCA? Are the samples positioning themselves based on the donor or their biological condition? What is the most extreme group of samples? How does this information relate to the other plots we produced above?\n\n\n# Let's clean some space up!\nrm(pcs)\nrm(pcaData)\nrm(log2dds)\ngc()\n\nNow that we have plotted all the main diagnostic information related to the dataset and we have a bit of a grasp of it, we can start thinking about testing for differentially expressed genes."
  },
  {
    "objectID": "pages/day1.html",
    "href": "pages/day1.html",
    "title": "Day 1",
    "section": "",
    "text": "Setup RStudio or Posit\nGet familiar with the Posit interface\nLearn about bulk RNA-seq data processing\nDownload the data needed for the workshop"
  },
  {
    "objectID": "pages/day1.html#using-rstudio-or-posit",
    "href": "pages/day1.html#using-rstudio-or-posit",
    "title": "Day 1",
    "section": "Using Rstudio or Posit",
    "text": "Using Rstudio or Posit\nIf RStudio is not installed on your computer, you can create a free account on posit.cloud. Create the account with your credentials and follow the instructions to create a new project. Once done, you should see something like this on your screen:\n\n\n\nThis is your working interface, the bottom right section shows your current file system (on the cloud) which is now pointed to the place where the Rproject you just created lives. The section on the left currently displays your console, where you can type R code interactively."
  },
  {
    "objectID": "pages/day1.html#communicating-with-r",
    "href": "pages/day1.html#communicating-with-r",
    "title": "Day 1",
    "section": "Communicating with R",
    "text": "Communicating with R\nYou should see your cursor on the left-hand side of the screen blinking. That window represents the R console. It can be used to “talk” with R through commands that it can understand!\n\nPrinting Text\nFor example, try typing the following in the console and check what comes out (a.k.a. the output):\n\n# Tell R to print out some words on screen with the \"print\" command\nprint(\"Hello World!\")\n\n[1] \"Hello World!\"\n\n\n\n\nCreating Variables\nOne of the main aspects of any programming language including R is the ability to create variables. You can think of variables as ways to store objects under any given name. Let’s take the previous example and store the Hello World! character (known as a string) in a variable that we call my_variable. The creation of a variable in R is classically done through the assignment operator <-.\n\n# Let's assign the statement to a variable (nothing happens when running this code)\nmy_variable <- \"Hello World!\"\n\n# Let's display the content of the new variable!\nprint(my_variable)\n\n[1] \"Hello World!\"\n\n\n\n💡 What happened in the top right part of your screen when you ran the code lines above? Check out the “environment” section, you should see that my_variable appeared there!\n\n\n\nMathematical Operations\nAs we said, the R language was built with statistics in mind, hence we can use it to perform mathematical operations with ease, much like a calculator.\n\nprint(6 / 2)\n\n[1] 3\n\n\n\n\nData Types: Vectors and Lists\nIn R, numbers, text and combination of the two can be represented in either vectors or lists. You can think of lists as an extension of vectors where elements can be heterogeneous and named. Let’s create a vector with numbers (with the c() command) and use it to display the way that functions work in R.\n\nmyvector <- c(1,2,3,4)\n\nLet’s find the mean value of this vector! Now we can either do this manually by summing all its elements and divide by their number, or we can use a function to do so, intuitively enough, the function we can use is the mean().\n\nmean(myvector)\n\n[1] 2.5\n\n\n\n💡 You can think of functions as a small piece of code that does something that normally would be done many times by repeating the code itself. Functions avoid the need for code repetition. We will acounter many functions later on, simple ones and very complex ones!\n\n\n\nData Types: Tables\nWithout going too much into the details of all the available objects used to store data in R, one of the most abundantly used is the data.frame. Think of data.frames as the R equivalent of Excel spreadsheets, so a way to store tabular data. As we will see later, pretty much all the data we are going to handle will be in the form of a data.frame or some of its other variations.\n\n# Let's create and display a data frame (a table) with four rows and two columns\ndata.frame(\"Class\"=c(\"a\",\"b\",\"c\",\"d\"), # First column\n            \"Quantity\"=c(1,10,4,6)) # Second column\n\n  Class Quantity\n1     a        1\n2     b       10\n3     c        4\n4     d        6\n\n\nYou have now instructed R to do something for you! We will ask it to do plenty more in the code chunks below!"
  },
  {
    "objectID": "pages/day1.html#creating-a-script",
    "href": "pages/day1.html#creating-a-script",
    "title": "Day 1",
    "section": "Creating a script",
    "text": "Creating a script\nIn the console we can type as many commands as we want and execute them sequentially. Nevertheless, commands typed in the console are lost the moment they are executed and if we want to execute them again we need to type everything back in the console… this is painful!\nA script is just a normal text file which groups a series of commands that R can execute sequentially, reading the file line-by-line. This is much better because we can then edit the file and save the changes!\nFollow the movie below to create an R script in Posit, the same applies to Rstudio, notice the .R extension at the end of the file name.\n\n\n\nThe new window that appeared on the upper left represents your R script. In here we can write R code which DOES NOT get executed immediately like in the console before.\n\n💡 In order to execute code from the script, highlight the code line you want to execute (or put your cursor line on it) and press ⌘+Enter on Mac or Ctrl+Enter on Windows."
  },
  {
    "objectID": "pages/day1.html#installing-packages",
    "href": "pages/day1.html#installing-packages",
    "title": "Day 1",
    "section": "Installing packages",
    "text": "Installing packages\nThe analyses that we are going to conduct require specific packages. In R, packages are collections of functions which help us perform standardized workflows. In the code chunk below, we instruct R to install the packages that we will need later on throughout the workshop.\n\n💡 Copy and paste this and the other code chunks from here to your R script to follow.\n\n\n# Install packages from Bioconductor\nif (!require(\"BiocManager\", quietly = TRUE))\n  install.packages(\"BiocManager\")\nBiocManager::install()\n\n# Install packages from CRAN\ninstall.packages(\"tidyr\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"googledrive\")\n\n# For differential expression\nBiocManager::install(\"vsn\")\nBiocManager::install(\"edgeR\")\ninstall.packages(\"statmod\")\n\n# For visualizations\ninstall.packages(\"hexbin\")\ninstall.packages(\"pheatmap\")\ninstall.packages(\"RColorBrewer\")\ninstall.packages(\"ggrepel\")\ninstall.packages(\"ggpubr\")\n\n# For conversion between gene IDs\nBiocManager::install(\"org.Hs.eg.db\")\n\n# For downstream analyses\ninstall.packages(\"msigdbr\")\nBiocManager::install(\"fgsea\")\nBiocManager::install(\"clusterProfiler\")\n\n# Remove garbage\ngc()\n\nDuring the installation, you will see many messages being displayed on your R console, don’t pay too much attention to them unless they are red and specify an error!\nIf you encounter any of these messages during installation, follow this procedure here:\n\n# R asks for package updates, answer \"n\" and type enter\n# Question displayed:\nUpdate all/some/none? [a/s/n]:\n\n# Answer to type:  \nn\n\n# R asks for installation from binary source, answer \"no\" and type enter\n# Question displayed:\nDo you want to install from sources the packages which need compilation? (Yes/no/cancel)\n\n# Answer to type:\nno\n\nHopefully all packages were correctly installed and now we can dive a bit deeper into the theoretical basics of RNA sequencing!"
  },
  {
    "objectID": "pages/day1.html#why-bulk-rna-sequencing",
    "href": "pages/day1.html#why-bulk-rna-sequencing",
    "title": "Day 1",
    "section": "Why bulk RNA sequencing?",
    "text": "Why bulk RNA sequencing?\nThe motivations behind an RNA sequencing experiment can be summarized between gathering a set of both quantitative but also qualitative observations.\n\n\n\n\n\n\n\nQuantitative\nQualitative\n\n\n\n\nIdentify differentially expressed genes\nAnnotate transcripts\n\n\nDetect different Isoform expression\nAlternative splicing analysis\n\n\n\nIdentify gene fusion events"
  },
  {
    "objectID": "pages/day1.html#experimental-workflow",
    "href": "pages/day1.html#experimental-workflow",
    "title": "Day 1",
    "section": "Experimental Workflow",
    "text": "Experimental Workflow\nA bulk RNA-seq experiment is articulated in the following steps:\n\nExperimental design: sample choice and hypothesis\nRNA extraction\ncDNA preparation: retrotranscription of RNA molecules\nLibrary preparation: fragmentation of cDNA molecules and ligation of adapters\nSequencing\nData processing: raw read QC\nData analysis: extract meaningful biological insights"
  },
  {
    "objectID": "pages/day1.html#how-can-we-design-a-bulk-rna-seq-experiment",
    "href": "pages/day1.html#how-can-we-design-a-bulk-rna-seq-experiment",
    "title": "Day 1",
    "section": "How can we design a bulk RNA-seq experiment?",
    "text": "How can we design a bulk RNA-seq experiment?\nA well thought-out experimental design is a crucial factor in achieving success. The best strategy will primarily depend on the experiment’s goals, the hypotheses being tested, and the type of data expected to be obtained.\n\nReplicates\nReplication is a key part of the scientific method and bulk RNA-seq experiments are no exception to the norm. Guideline suggest to perform 2-5 replicates for each condition of interest!\n\n🤔 Do you know what the differences between a technical and biological replicates are?\n\n\n\n\nTechnical Replicates: use the same biological specimen (sample) from the same experimental condition to repeat the technical or experimental steps in order to accurately measure technical variation and remove it during analysis. These are normally dispensable given the low technical variation with NGS technologies.\nBiological Replicates: use different biological samples of the same condition to measure the biological variation between samples. Of key importance for the analysis. The higher the number of biological replicates, the more precise the estimate of average gene expression. They’re even more important than sequencing depth in defining differentially expressed genes with confidence.\n\n\nAvoiding batch effects!\nBatch effect refers to the unwanted variability in data that arises due to differences in how samples are processed, handled, or analyzed across different experimental batches or conditions, rather than being due to the biological variation of interest.\nSources of batch effect can arise from:\n\nsample collection strategies\nprocessing differences\nequipment and instrumentation\nlibrary preparation time\nsequencing time\n\n\n💡 If you cannot avoid batch effects, do not confound you experiment by batch but instead randomize samples across batches!\n\nWhat follows is a basic yet intuitive visualization of what the above phrase means in practice… in a poorly-designed experiment:\n\n\n\nAnd in a well-designed experiment with following analyses in mind:\n\n\n\nThis approach ensures that any potential batch effects — such as differences in RNA extraction, handling, or processing — are equally represented in both the control and treatment groups, thereby helping to isolate biological variation from technical noise.\ne.g If you need to extract RNA in two batches due to the number of samples, avoid extracting only control samples in one batch and only treated samples in the second one. Doing so could introduce batch-specific technical variations that would make it difficult to differentiate between true biological differences and technical artifacts. Instead, ensure that you equally distribute control and treated samples across both batches.\n\n🤔 Could you think about another example of how to avoid batch effect in your experimental set up?"
  },
  {
    "objectID": "pages/day1.html#how-do-we-go-from-mrna-to-sequences",
    "href": "pages/day1.html#how-do-we-go-from-mrna-to-sequences",
    "title": "Day 1",
    "section": "How do we go from mRNA to sequences?",
    "text": "How do we go from mRNA to sequences?\n\nGathering RNA from cells\nThe first step is of course to materially extract RNA molecules from our set of cells of interest!\nMost commonly used extraction methods are organic extraction methods (phenol-containing solutions) or filter-based (membranes). Then, in order to eliminate DNA contamination in your sample and increase RNA purity, DNAse treatment is performed. Certain forms of contamination can be detected using UV spectroscopy and the calculation of absorbance ratios. Good quality RNA will have an A260/280 ratio of 1.7 to 2.1 and A260/230 of 2.0 to 2.2. A260/280 lower than 1.7 may indicate protein contamination, whereas A260/230 less than 1.8 may indicate the presence of organics (e.g. phenol or guanidine) leftover from the extraction protocol.\n\n🚨 Degradation of RNA breaks up long RNA molecules into shorter fragments, that are more difficult to assemble bioinformatically, and therefore RNA sequence information can be lost!\n\nFollowing that, RNA is quantified and its integrity evaluated (by agarose gel electrophoresis or by Bioanalyzer or Tape station). With both methods you should recognize the most abundant RNAs in our cells: the ribosomal subunits 18S and 28S (that should be twice 18S). The image below shows 3 bioanalyzer profiles at decreasing levels of RIN (RNA Integrity Number).\n\n\n\n\n🤔 Based on what we’ve said about batch effects, would you use the same RNA extraction protocol or different ones for your samples?\n\n\n\nInterested in different species of RNA?\nAs we know RNA can come in many forms and functions, so depending on your research interest, you might be prompted to look at specific RNA species over others. This means that we need to enrich for specific sets of RNA molecules among the many ones that cells produce to function! Below we can find a series of protocols optimized to capture different RNA species:\n\n\n\n\n\n\n\n\nMethod\nApplication\nLimitations\n\n\n\n\nPoly(A) selection\nmRNA sequencing\nExcludes non-polyadenilated species (rRNAs, tRNAs)\n\n\nrRNA Depletion\nmRNA, small RNAs and lncRNAs\nCan reduce total RNA yield\n\n\nTotal RNA-seq\nComprehensive transcriptome analysis\nHigh rRNA content and reduced overall sensitivity\n\n\nmiRNA Enrichment\nSmall RNA sequencing (miRNAs, snoRNAs, etc.)\nExcludes large RNAs, and only focuses on small RNA species\n\n\nCapture-based Enrichment\nTargeted RNA sequencing\nOnly focuses on specific sequences, not suitable for global analysis\n\n\n\n\n\nProducing a library\nStarting from our precious mRNA molecule that has been isolated from our sample, we transform it into DNA by means of retrotranscription, this process creates what is known as cDNA. cDNA molecules can be very large and due to technical constraints we need to fragment them into smaller pieces. All these pieces are then ligated to a set of sequences known as adapters.\n\n\n\nImportantly, Since there are many genomic regions that generate transcripts from both strands, identifying the polarity of a given transcript provides essential information about the possible function of a gene.\nHowever, in canonical NON-STRANDED library preparation random primers are used for first- and second-strand synthesis of cDNA. The resulting sequencing products from the two antisense transcripts are identical and cannot be distinguished when sequenced. Thus, information about directionality is lost during cDNA synthesis.\n\n\n\nOn the contrary, STRAND-SPECIFIC library preparation distinguishes the first and second strands of cDNA by incorporating uracil instead of thymine to label the second strand. After adapter ligation, amplification of the second strand is blocked. This can be accomplished by performing uracil-specific digestion before amplification or by using a DNA polymerase that is unable to amplify uracil-containing templates. As a result, all sequencing products from a particular RNA molecule will have the same orientation.\n\n\nNext Generation Sequencing\nNext Generation Sequencing technologies (Illumina/PacBio) allow experimenters to capture the entire genetic information in a sample in a completely unsupervised manner. The process works with an approach called sequencing-by-synthesis or SBS for short.\n\n💡 Great info can be found at the Illumina Knowledge page\n\nThis means that strands are sequenced by re-building them using the natural complementarity principle of DNA with fluorescently labelled bases which get detected and decoded into sequences. On illumina flow-cells this process happens in clusters, to allow for proper signal amplification and detection, as shown in the movie below.\n\n\n\n\nAs we have seen in the video, adapter sequences are used by the sequencing machine to hybridize cDNA fragments to the flow cell and form sequencing clusters.\nA few key parameters to consider when using NGS technologies (and this holds true for all involved omics approaches) include:\n\nSequencing Depth: as the name suggests, this represents the final objective in terms of number of reads obained in the experiment, we can go shallow for a quick snapshot of highly expressed genes (5 to 30 million reads), or very deep to catch that rarely expressed variant we are interested in (150 to 200 million reads)!\nRead Length: this is another parameter set by the operator and determines the amount of snapshots we take of the flowcell with its clusters after each hibridization round determining “how far into” the cDNA molecule we look (typically 50 to 75 bp) - longer reads are useful is we are aiming for novel transcript assembly and isoform identification.\nSequencing Mode: we can either sequence our library from one side in single-end mode or from both sides of each insert using paired-end sequencing which generates two reads per fragment. The latter is more expensive but fondamental for the detection of gene isoforms since we get more information.\n\n\n\n\n\n💡 Additional information and guidelines on sequencing depth and read lenght can be found on ENCODE Consortium’s website!"
  },
  {
    "objectID": "pages/day1.html#raw-sequencing-output",
    "href": "pages/day1.html#raw-sequencing-output",
    "title": "Day 1",
    "section": "Raw Sequencing Output",
    "text": "Raw Sequencing Output\nThe raw output of any sequencing run consists of a series of sequences (called reads). These sequences can have varying length based on the run parameters set on the sequencing platform. Nevertheless, they are made available for humans to read under a standardized file format known as FASTQ. This is the universally accepted format used to encode sequences after sequencing. An example of real FASTQ file with only two reads is provided below.\n\n@Seq1\nAGTCAGTTAAGCTGGTCCGTAGCTCTGAGGCTGACGAGTCGAGCTCGTACG\n+\nBBBEGGGGEGGGFGFGGEFGFGFGGFGGGGGGFGFGFGGGFGFGFGFGFG\n@Seq2\nTGCTAAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGC\n+\nEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n\nFASTQ files are an intermediate file in the analysis and are used to assess quality metrics for any given sequence. The quality of each base call is encoded in the line after the + following the standard Phred score system.\n\n💡 Since we now have an initial metric for each sequence, it is mandatory to conduct some standard quality control evaluation of our sequences to eventually spot technical defects in the sequencing run early on in the analysis."
  },
  {
    "objectID": "pages/day1.html#quality-metrics-inspection",
    "href": "pages/day1.html#quality-metrics-inspection",
    "title": "Day 1",
    "section": "Quality Metrics Inspection",
    "text": "Quality Metrics Inspection\nComputational tools like FastQC aid with the visual inspection of per-sample quality metrics from NGS experiments. Some of the QC metrics of interest to consider include the ones listed below, on the left are optimal metric profiles while on the right are sub-optimal ones:\n\nPer-base Sequence Quality  This uses box plots to highlight the per-base quality along all reads in the sequencing experiment, we can notice a physiological drop in quality towards the end part of the read.\n\n\nPer-sequence Quality Scores  Here we are plotting the distribution of Phred scores across all identified sequences, we can see that the high quality experiment (left) has a peak at higher Phred scores values (34-38).\n\n\nPer-base Sequence Content  Here we check the sequence (read) base content, in a normal scenario we do not expect any dramatic variation across the full length of the read since we should see a quasi-balanced distribution of bases.\n\n\nPer-sequence GC Content  GC-content referes to the degree at which guanosine and cytosine are present within a sequence, in NGS experiments which also include PCR amplification this aspect is crucial to check since GC-poor sequences may be enriched due to their easier amplification bias. In a normal random library we would expect this to have a bell-shaped distribution such as the one on the left.\n\n\nSequence Duplication Levels  This plot shows the degree of sequence duplication levels. In a normal library (left) we expect to have low levels of duplication which can be a positive indicator of high sequencing coverage.\n\n\nAdapter Content  In NGS experiments we use adapters to create a library. Sometimes these can get sequenced accidentally and end up being part of a read. This phenomenon can be spotted here and corrected later using a computational approach called adapter trimming, visible in next section’s figure."
  },
  {
    "objectID": "pages/day1.html#read-alignment",
    "href": "pages/day1.html#read-alignment",
    "title": "Day 1",
    "section": "Read Alignment",
    "text": "Read Alignment\nOnce we are satisfied with the quality of our pool of sequences, we need to map them back to the transcripts to which they belonged originally when we produced cDNA molecules from RNA. This process of mapping is needed to understand from which genes were transcripts generated and therefore is an essential and very important step of data processing!\n\n\nAlignment of trimmed reads to a reference genome or transcriptome.\n\n\nBut what is a reference genome really?\nWhen we perform an RNA-seq experiment, we need to understand where the millions of reads that we get come from in the genome, in other words, which genes (by being transcribed) contribute to what degree to the amount of signal that we get in each experiment! Since every mRNA (hence cDNA) is different among individuals, we can use a general genome which is manually built and onto which we can place our reads to check for matches and mismatches.\n\n💡 The Human Genome Project for example released the very first assembled reference genome in 2003, using sequencing data coming from at least 10 different individuals and containing more than 3 billion bases! Currently, the most used “build” of the human genome is the one called GRCh37, released in 2013.\n\nTools like STAR and BWA-MEM are designed to achieve great speed and accuracy for the computationally expensive task of read alignment.\nThe results of the alignment procedure is a different set of files in SAM (Standard Alignment Map) format which get compressed into their binary representation, BAM files. These are usually one for each analyzed sample and encode the position of all the identified reads along the genome as well as alignment quality metrics for QC, which can be carried out with tools like MultiQC.\n\n\nIGV screenshot of a single BAM file showing reads at the GAPDH locus.\n\n\n💡 All of these pre-processing steps, which are computationally expensive, are usually integrated in command-line pipelines which connect inputs and outputs of these difference procedures in a streamlined manner. An example is the RNA-seq pipeline provided by the nf-core community."
  },
  {
    "objectID": "pages/day1.html#counting-transcripts",
    "href": "pages/day1.html#counting-transcripts",
    "title": "Day 1",
    "section": "Counting Transcripts",
    "text": "Counting Transcripts\nAfter sequences have been aligned to their respective place on the genome, it is time to actually count how many times a given sequence is found on any given gene (or transcripts, or exons or others..), this will actually be our gene expression measurement!\n\n\n\nThere are many ways to achieve this task but among the most used is the featureCounts tool. In the end, for every sample, we will end up with a number for each gene (or transcripts), these are called gene (transcript) counts.\nThese are usually summarized in a table, called gene expression table, where each sample is a column and each row a different gene. We will now load one and take a closer look, this will be our starting point in the hands-on analysis of bulk RNA-seq data.\n\n💡 What is the difference between a gene and a transcript?"
  },
  {
    "objectID": "pages/day1.html#what-data-are-we-going-to-use-what-is-our-question",
    "href": "pages/day1.html#what-data-are-we-going-to-use-what-is-our-question",
    "title": "Day 1",
    "section": "What data are we going to use? What is our question?",
    "text": "What data are we going to use? What is our question?\nWe will load a table of data from this study on tumor-infiltrating CD8+ T-cells. The original data supporting the findings of the study has been deposited on the Gene Expression Omnibus (GEO) data portal under accession number GSE120575. This is the place where all studies publish the processed sequencing data from their analysis in order for other researchers to download it and reproduce their findings or test their own hypotheses.\n\n\n\nBriefly, the authors collected bulk RNA-seq data from different subpopulations of transgenic CD8+ T cells including ones known as exhausted which are particularly relevant in the context of cancer immunotherapy. These cells are in fact consistently exposed to antigens in the tumor microenvironment and become dysfunctional, unable to fight cancer cells which are therefore free to keep expanding. Understanding and preventing the process of T cell exhaustion poses and interesting and relevant challenge in the field of immunotherapies for a variety of cancer types."
  },
  {
    "objectID": "pages/day1.html#loading-the-data",
    "href": "pages/day1.html#loading-the-data",
    "title": "Day 1",
    "section": "Loading The Data",
    "text": "Loading The Data\nWe have already downloaded the data and inserted it in a Google Drive folder organizing it as follows:\n\nraw_counts.csv: the gene by sample matrix containing the number of times each gene is detected in each sample (our gene expression values)\nsamples_info.csv: the table containing samples information, known as metadata, which tells us about the biological meaning of each sample\n\nOpen the folder through your Google Drive (this step is important), check the presence of the files in the browser and then only AFTER having done this, run the code below. After having opened the Google Drive folder, follow the code chunk below where we are going to load the data and create two new variables in our R session, one for each table.\n\n🚨 NOTE: After you run the code below, look into your R console and check if you are prompted to insert your Google account information. Do so and then follow the instructions to connect to your Google account in order to download the data from the shared MOBW2025 folder!\n\n\n# Load installed packages with the \"library()\" function\nlibrary(\"dplyr\")\nlibrary(\"googledrive\")\n\n# Load files\nfiles <- drive_ls(path=\"MOBW2025\")\n\n# File paths with URL\ncounts <- files[files$name == \"raw_counts.csv\",] %>% drive_read_string() %>% read.csv(text = .) %>% as.data.frame()\nrownames(counts) <- counts$X\ncounts$X <- NULL\n\nsamples <- files[files$name == \"samples_info.csv\",] %>% drive_read_string() %>% read.csv(text = .) %>% as.data.frame()\nrownames(samples) <- samples$X \nsamples <- samples[,c(\"Donor\",\"SampleGroup\",\"sex\")]\n\nWe can now explore the data that we have just loaded in the current R session to familiarize with it.\n\n# Check out the counts\nhead(counts, 10)\n\n\n\n\n\n \n  \n      \n    BSSE_QGF_204446 \n    BSSE_QGF_204447 \n    BSSE_QGF_204448 \n    BSSE_QGF_204449 \n    BSSE_QGF_204450 \n    BSSE_QGF_204451 \n    BSSE_QGF_204452 \n    BSSE_QGF_204453 \n    BSSE_QGF_204458 \n    BSSE_QGF_204459 \n    BSSE_QGF_204460 \n    BSSE_QGF_204461 \n    BSSE_QGF_204462 \n    BSSE_QGF_204463 \n    BSSE_QGF_204464 \n    BSSE_QGF_204465 \n  \n \n\n  \n    ENSG00000228572 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000182378 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000226179 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000281849 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000280767 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000185960 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    LRG_710 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000237531 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000198223 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000265658 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n\n\n\n\n\nWe can then check the shape of our counts table (i.e. how many different transcripts we are detecting and how many different samples?)\n\n🤔 How many rows are we expecting to be present in our counts table? hint: think of the type of experiment and the readout we are expecting!\n\nWe can see that our table contains count information for 16 samples.\n\n💡 In R, these table object are called data.frames, tibbles are just like them but with some improved functionalities provided by the tidyverse library.\n\nWe can also inspect the metadata from the samples which is stored in the samples variable we created above."
  },
  {
    "objectID": "pages/day1.html#exploring-metadata",
    "href": "pages/day1.html#exploring-metadata",
    "title": "Day 1",
    "section": "Exploring Metadata",
    "text": "Exploring Metadata\nMetadata refers to that class of accessory data to the main experimental readout. In the case of this published dataset, the main data refers to the actual gene expression table with the associated counts measurement for each sample. Each sample then has associated information used to further describe it (e.g. type of cells, patient ID, treatment status, experimental batch…), as we have previously seen, this information is instrumental to bioinformaticians to avoid pitfalls in the analysis. In the case of our data, this information is contained in the samples table. We can use R’s functionality to explore it and visualize it in order to get an idea about the dataset!\n\n# What does the table look like?\nsamples\n\n\n\n\n\n \n  \n      \n    Donor \n    SampleGroup \n    sex \n  \n \n\n  \n    BSSE_QGF_204446 \n    HD276 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204447 \n    HD276 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204448 \n    HD276 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204449 \n    HD276 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204450 \n    HD280 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204451 \n    HD280 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204452 \n    HD280 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204453 \n    HD280 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204458 \n    HD286 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204459 \n    HD286 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204460 \n    HD286 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204461 \n    HD286 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204462 \n    HD287 \n    Trest \n    Female \n  \n  \n    BSSE_QGF_204463 \n    HD287 \n    Ttumor \n    Female \n  \n  \n    BSSE_QGF_204464 \n    HD287 \n    Teff \n    Female \n  \n  \n    BSSE_QGF_204465 \n    HD287 \n    Tex \n    Female \n  \n\n\n\n\n\n\n# What is the shape of this samples table?\ndim(samples)\n\n[1] 16  3\n\n\nIn this case, this samples table has as many rows (16) as there are samples (which in turn is equal to the number of columns in the counts table), with columns containing different types of information related to each of the samples in the analysis.\n\nMaking graphs and figures in R\nWe can take advantage of the way R handles tabular data to easily plot information and get a visual sense of the dataset. Exploring data in this way is very important, it allows us to detect flaws and weird effects in the data early on, so to avoid any misinterpretation which can greatly impact downstream analysis. For example, taking our samples table, we can ask whether covariates are balanced in the data or some categories are more/less represented than others.\nFor example, let’s say we want to understand how many sample in our data come from patients with different genders!\nWe can use R’s go-to plotting library called ggplot2 to feed it the samples table and tell it what we want to plot and how.\n\n💡 when visualizing data, it is important to understand the variables we want to work with. Are we plotting univariate or bivariate data? Are we interested in continuous or categorical variables?\n\nLet’s first plot a barplot with gender information, then we’ll discuss a bit more about the code and ggplot’s grammar of graphics.\n\nlibrary(\"ggplot2\")\n\n# Simple and ugly\nggplot(samples, aes(x=sex)) + geom_bar()\n\n\n\n\n\n\n\n\nLet’s make a nicer one! Nice graphs convey information more easily and (most importantly) efficiently!\n\n# A bit more work but nicer and more intuitive\nggplot(samples, aes(x=sex, fill=sex)) + \n  geom_bar(width=0.7) +\n  scale_fill_manual(values=c('Female'='#FD96A9', 'Male'='#BBCBCB')) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThat’s better! The trick to ggplot is the ability to map variables to the x and y axes with the aesthetics function aes(). this is just the first layer, then from this we can build up our plot deciding what plot to draw (in this case a barplot hence geom_bar()) and further customize it.\nWe can use the same approach to understand how experimental categories are distributed across our data. In a real-life scenario, we should already know this information because we were the ones designing the experiment in the first place, so we should know how many replicates we need!\n\n🚀 Try to draw a barplot showing the amount of sample that we have for each experimental condition in the data!"
  },
  {
    "objectID": "pages/day1.html#savingloading-files",
    "href": "pages/day1.html#savingloading-files",
    "title": "Day 1",
    "section": "Saving/Loading Files",
    "text": "Saving/Loading Files\nLet’s save this object with samples information in a file on this cloud session, this might be needed later if we end up in some trouble with the R session! This is a file format where columns are separated by commas. You might be familiar with this format if you have worked quite a bit in Excel. In R, we can save tabular data with the write.table() function specifying the location (the file name) we want. This is useful in the case our R session dies or we decide to interrupt it. In this case we will not have to run the whole analysis from the beginning and we can just source the file and load it!\n\nwrite.table(samples, \"samples_table.csv\", sep = \",\", quote = FALSE)\n\nWe can load the object back into the current session by using the following code line:\n\nsamples <- read.table(\"samples_table.csv\", sep = \",\")\n\n\n💡 We will also repeat this procedure with the results of the differential expression analysis in order to avoid repeating work we have already done in case of any trouble!\n\nNow that we have our objects correctly loaded, we can dive into the actual RNA-seq analysis."
  },
  {
    "objectID": "pages/preface.html",
    "href": "pages/preface.html",
    "title": "Preface",
    "section": "",
    "text": "Omics technologies can be applied to a biological system of interest to obtain a snapshot of the underlying biology at a resolution that has never before been possible. These technologies provide a holistic yet detailed view of biological processes and interactions at a very large scale.\n\n\n\nMany areas of research can be classified as omics. Examples include proteomics, transcriptomics, genomics, metabolomics and epigenomics, which correspond to global analyses of proteins, RNA, genes, metabolites, and methylated DNA or modified histone proteins.\nExperiments involving Omics technologies usually require a specific set of skills to be analyzed which fall under the umbrella term of bioinformatics."
  },
  {
    "objectID": "pages/preface.html#but-why-are-we-talking-about-high-throughput-data",
    "href": "pages/preface.html#but-why-are-we-talking-about-high-throughput-data",
    "title": "Preface",
    "section": "But why are we talking about high throughput data? 🤌🏼",
    "text": "But why are we talking about high throughput data? 🤌🏼\nAs we will see, biological phenomena are extremely complex and hard to make sense of! Just think about the sheer size of the information (how much?) contained in our genome in the form of words composed by just 4 letters and the majority of them don’t even mean anything! 🤯\n\n💡 Do you know what is the amount of information contained in the genome that is actually used to build proteins?\n\nLater we will dive into the world of Next Generation Sequencing technologies (NGS) and how they have revolutionized the way we can collect information about the molecules around which life encodes and transfers its information, DNA, RNA and proteins.\n\n\n\nGiven the scale, size and complexity (hence high-throughput) of the data generated by these technologies, human power is not enough to get them processed in a reasonable amount of time… that’s where dumb computers come in the picture!"
  },
  {
    "objectID": "pages/preface.html#bioinfowhattt",
    "href": "pages/preface.html#bioinfowhattt",
    "title": "Preface",
    "section": "Bioinfowhattt?",
    "text": "Bioinfowhattt?\nLet’s look at what ChatGPT outputs when asked the question: “What do you think we mean when we say bioinformatics?”\n\nWhen we say “bioinformatics,” we’re typically referring to the use of computer science, statistics, and data analysis techniques to understand complex biological data. This often involves analyzing genetic sequences (like DNA or RNA), protein structures, or other molecular biology data to make sense of biological systems, identify patterns, and answer questions related to health, disease, evolution, and more. It’s about bridging biology with technology to unlock insights from vast amounts of biological data.\n\nBut should we really trust it?\nThis course is aimed at giving you a sense of the possibilities and challenges that come with analyzing high-throughput data so that you can get a feeling for what your answer to that question might be!"
  },
  {
    "objectID": "pages/preface.html#do-i-need-to-know-how-to-program-computers",
    "href": "pages/preface.html#do-i-need-to-know-how-to-program-computers",
    "title": "Preface",
    "section": "Do I need to know how to program computers?",
    "text": "Do I need to know how to program computers?\nIn short… YES! But don’t be intimated by this, we will walk through the computer code in the workshop together, trying to understand it by functionality instead of blindly learning to type some letters on a screen.\nIn particular, bioinformatics has historically revolved around the use of computer terminals (or command-line, CLI), using a terminal basically feels like looking inside the void soul of your computer, a spot of complete darkness, just like you imagine it.\n\n☠️ If you dare, you can look into the void by typing ⌘+Space and typing “Terminal” on Mac or Win+R -> type “cmd” -> press Enter on Windows!\n\nMost data-intensive operations in bioinformatics are handled by specialized “tools” (computer programs) that work in this environment, where we need to tell explicitly the computer what to do instead of pushing flashy buttons on the screen, something a bit different than what we are normally used to. This is because your computer’s Operating System is designed to make its use an actually enjoyable experience for you, but deep down everything ends in the void.\n\n\n\nIn this workshop we are not going to look at the computer’s terminal archaic way of communicating, we are instead going to instruct our computer on what we want to do by using a more modern and comprehensible language known as R."
  },
  {
    "objectID": "pages/preface.html#what-is-r",
    "href": "pages/preface.html#what-is-r",
    "title": "Preface",
    "section": "What is R? 🤖",
    "text": "What is R? 🤖\nR is a programming language, what this means is that some people originally created it as a way for humans to write code that can be understood by a computer to perform simple or complex operations! Easy!\nThe main objectives of R as a language are to facilitate their users in performing tasks related to statistics and data analysis, including data visualization and representation.\n\n💡 Have you ever heard of programming languages? Do you know any? Have you had any experience with R?"
  }
]